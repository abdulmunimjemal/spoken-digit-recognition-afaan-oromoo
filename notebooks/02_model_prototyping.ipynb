{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02. Model Prototyping\n",
                "\n",
                "In this notebook, we define the PyTorch Dataset class to handle audio loading and preprocessing, and we design a Convolutional Neural Network (CNN) for classification.\n",
                "\n",
                "## 1. Custom Dataset Class\n",
                "We need a class that:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import torch\n",
                "import torchaudio\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "class SpokenDigitDataset(Dataset):\n",
                "    def __init__(self, data_path, sample_rate=16000, n_mels=64, max_duration=1.0):\n",
                "        self.data_path = data_path\n",
                "        self.sample_rate = sample_rate\n",
                "        self.max_length = int(sample_rate * max_duration)\n",
                "        self.file_list = []\n",
                "        self.labels = []\n",
                "        \n",
                "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
                "            sample_rate=sample_rate, n_mels=n_mels)\n",
                "        self.db_transform = torchaudio.transforms.AmplitudeToDB()\n",
                "        \n",
                "        self._load_dataset()\n",
                "        \n",
                "    def _load_dataset(self):\n",
                "        for label in range(10):\n",
                "            label_dir = os.path.join(self.data_path, str(label))\n",
                "            if not os.path.isdir(label_dir): continue\n",
                "            # We look for .ogg and .wav files (converted from m4a)\n",
                "            files = []\n",
                "            for ext in ['*.ogg', '*.wav']:\n",
                "                files.extend(glob.glob(os.path.join(label_dir, ext)))\n",
                "                \n",
                "            for f in files:\n",
                "                self.file_list.append(f)\n",
                "                self.labels.append(label)\n",
                "                \n",
                "    def __len__(self):\n",
                "        return len(self.file_list)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        file_path = self.file_list[idx]\n",
                "        label = self.labels[idx]\n",
                "        \n",
                "        waveform, sr = torchaudio.load(file_path)\n",
                "        if sr != self.sample_rate:\n",
                "            waveform = torchaudio.transforms.Resample(sr, self.sample_rate)(waveform)\n",
                "        \n",
                "        if waveform.shape[0] > 1:\n",
                "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
                "            \n",
                "        length_adj = self.max_length - waveform.shape[1]\n",
                "        if length_adj > 0:\n",
                "            waveform = torch.nn.functional.pad(waveform, (0, length_adj))\n",
                "        else:\n",
                "            waveform = waveform[:, :self.max_length]\n",
                "            \n",
                "        melspec = self.mel_transform(waveform)\n",
                "        melspec = self.db_transform(melspec)\n",
                "        \n",
                "        return melspec, label\n",
                "\n",
                "dataset = SpokenDigitDataset('../data/processed')\n",
                "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
                "print(f\"Total samples: {len(dataset)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. CNN Model Architecture\n",
                "We use a simple 4-layer CNN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "\n",
                "class SimpleCNN(nn.Module):\n",
                "    def __init__(self, num_classes=10):\n",
                "        super(SimpleCNN, self).__init__()\n",
                "        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 3, 1, 1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 3, 1, 1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        self.conv4 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.AdaptiveAvgPool2d((4, 4)))\n",
                "        self.fc = nn.Sequential(nn.Flatten(), nn.Linear(128*4*4, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, num_classes))\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        x = self.conv2(x)\n",
                "        x = self.conv3(x)\n",
                "        x = self.conv4(x)\n",
                "        return self.fc(x)\n",
                "\n",
                "model = SimpleCNN()\n",
                "print(model)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
